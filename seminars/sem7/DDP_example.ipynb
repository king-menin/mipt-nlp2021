{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f616341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-31 06:53:36.956674: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Using pad_token, but it is not set yet.\n",
      "Cached features file ./cache/d0a09c10918f168eb8e1993f46ba60f46e10f9a277de99693e3610d1_a47bf07903341f139aa10616f800ba468e70a3ce9daec916df618c2f.cache\n",
      "Loading cached features from file\n"
     ]
    }
   ],
   "source": [
    "!python tokenize_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b82b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-31 07:05:01.695368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Using pad_token, but it is not set yet.\n",
      "Cached features file ./cache/d0a09c10918f168eb8e1993f46ba60f46e10f9a277de99693e3610d1_a47bf07903341f139aa10616f800ba468e70a3ce9daec916df618c2f.cache\n",
      "Loading cached features from file\n",
      "Loss 2.979\n",
      "Loss 2.890\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python one_gpu.py --batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e72f7bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-31 07:10:37.824714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-31 07:10:37.825120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-31 07:10:37.825119: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-31 07:10:37.825120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "sem6-0:1208:1208 [0] NCCL INFO Bootstrap : Using [0]eth0:10.233.81.216<0>\n",
      "sem6-0:1208:1208 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "sem6-0:1208:1208 [0] NCCL INFO NET/IB : No device found.\n",
      "sem6-0:1208:1208 [0] NCCL INFO NET/Socket : Using [0]eth0:10.233.81.216<0>\n",
      "NCCL version 2.4.8+cuda10.1\n",
      "sem6-0:1211:1211 [3] NCCL INFO Bootstrap : Using [0]eth0:10.233.81.216<0>\n",
      "sem6-0:1209:1209 [1] NCCL INFO Bootstrap : Using [0]eth0:10.233.81.216<0>\n",
      "sem6-0:1211:1211 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "sem6-0:1209:1209 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "sem6-0:1211:1211 [3] NCCL INFO NET/IB : No device found.\n",
      "sem6-0:1209:1209 [1] NCCL INFO NET/IB : No device found.\n",
      "sem6-0:1211:1211 [3] NCCL INFO NET/Socket : Using [0]eth0:10.233.81.216<0>\n",
      "sem6-0:1209:1209 [1] NCCL INFO NET/Socket : Using [0]eth0:10.233.81.216<0>\n",
      "sem6-0:1210:1210 [2] NCCL INFO Bootstrap : Using [0]eth0:10.233.81.216<0>\n",
      "sem6-0:1210:1210 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "sem6-0:1210:1210 [2] NCCL INFO NET/IB : No device found.\n",
      "sem6-0:1210:1210 [2] NCCL INFO NET/Socket : Using [0]eth0:10.233.81.216<0>\n",
      "sem6-0:1208:1385 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\n",
      "sem6-0:1209:1387 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\n",
      "sem6-0:1211:1386 [3] NCCL INFO Setting affinity for GPU 3 to ffffff00,0000ffff,ff000000\n",
      "sem6-0:1210:1388 [2] NCCL INFO Setting affinity for GPU 2 to ffffff00,0000ffff,ff000000\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 00 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 01 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 02 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 03 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 04 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 05 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 06 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 07 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 08 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 09 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 10 :    0   1   2   3\n",
      "sem6-0:1208:1385 [0] NCCL INFO Channel 11 :    0   1   2   3\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 00 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 00 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 00 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 00 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 01 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 01 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 01 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 01 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 02 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 02 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 02 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 02 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 03 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 03 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 03 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 03 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 04 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 04 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 04 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 04 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 05 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 05 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 05 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 05 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 06 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 06 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 06 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 06 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 07 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 07 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 07 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 07 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 08 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 08 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 08 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 08 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 09 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 09 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 09 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 09 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 10 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 10 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 10 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 10 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1210:1388 [2] NCCL INFO Ring 11 : 2[10] -> 3[12] via P2P/IPC\n",
      "sem6-0:1211:1386 [3] NCCL INFO Ring 11 : 3[12] -> 0[0] via P2P/IPC\n",
      "sem6-0:1209:1387 [1] NCCL INFO Ring 11 : 1[4] -> 2[10] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Ring 11 : 0[0] -> 1[4] via P2P/IPC\n",
      "sem6-0:1208:1385 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\n",
      "sem6-0:1211:1386 [3] NCCL INFO comm 0x7fa290002400 rank 3 nranks 4 cudaDev 3 nvmlDev 12 - Init COMPLETE\n",
      "sem6-0:1210:1388 [2] NCCL INFO comm 0x7fa538002400 rank 2 nranks 4 cudaDev 2 nvmlDev 10 - Init COMPLETE\n",
      "sem6-0:1208:1385 [0] NCCL INFO comm 0x7f8ddc002400 rank 0 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE\n",
      "sem6-0:1208:1208 [0] NCCL INFO Launch mode Parallel\n",
      "sem6-0:1209:1387 [1] NCCL INFO comm 0x7f0c74002400 rank 1 nranks 4 cudaDev 1 nvmlDev 4 - Init COMPLETE\n",
      "Using pad_token, but it is not set yet.\n",
      "Cached features file ./cache/d0a09c10918f168eb8e1993f46ba60f46e10f9a277de99693e3610d1_a47bf07903341f139aa10616f800ba468e70a3ce9daec916df618c2f.cache\n",
      "Loading cached features from file\n",
      "Using pad_token, but it is not set yet.\n",
      "Cached features file ./cache/d0a09c10918f168eb8e1993f46ba60f46e10f9a277de99693e3610d1_a47bf07903341f139aa10616f800ba468e70a3ce9daec916df618c2f.cache\n",
      "Loading cached features from file\n",
      "Using pad_token, but it is not set yet.\n",
      "Cached features file ./cache/d0a09c10918f168eb8e1993f46ba60f46e10f9a277de99693e3610d1_a47bf07903341f139aa10616f800ba468e70a3ce9daec916df618c2f.cache\n",
      "Loading cached features from file\n",
      "Using pad_token, but it is not set yet.\n",
      "Cached features file ./cache/d0a09c10918f168eb8e1993f46ba60f46e10f9a277de99693e3610d1_a47bf07903341f139aa10616f800ba468e70a3ce9daec916df618c2f.cache\n",
      "Loading cached features from file\n",
      "Loss 3.285\n",
      "Loss 3.298\n",
      "Loss 3.181\n",
      "Loss 3.290\n",
      "Loss 2.851\n",
      "Loss 2.953\n",
      "Loss 2.897\n",
      "Loss 2.849\n",
      "Loss 3.029Loss 3.113\n",
      "\n",
      "Loss 2.955\n",
      "Loss 3.009\n",
      "Loss 2.937Loss 2.839\n",
      "\n",
      "Loss 2.990\n",
      "Loss 3.058\n",
      "Loss 2.943Loss 3.087\n",
      "\n",
      "Loss 3.076\n",
      "Loss 2.963\n",
      "Loss 2.930\n",
      "Loss 3.066\n",
      "Loss 3.008Loss 2.906\n",
      "\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"ddp_example.py\", line 82, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"ddp_example.py\", line 82, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"ddp_example.py\", line 82, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"ddp_example.py\", line 82, in <module>\n",
      "    main()\n",
      "  File \"ddp_example.py\", line 76, in main\n",
      "    main()\n",
      "  File \"ddp_example.py\", line 76, in main\n",
      "    main()\n",
      "  File \"ddp_example.py\", line 76, in main\n",
      "    main()\n",
      "  File \"ddp_example.py\", line 76, in main\n",
      "    loss.backward()\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/tensor.py\", line 185, in backward\n",
      "    loss.backward()\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/tensor.py\", line 185, in backward\n",
      "    loss.backward()\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/tensor.py\", line 185, in backward\n",
      "        torch.autograd.backward(self, gradient, retain_graph, create_graph)torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 127, in backward\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 127, in backward\n",
      "    loss.backward()    \n",
      "torch.autograd.backward(self, gradient, retain_graph, create_graph)  File \"/home/user/conda/lib/python3.7/site-packages/torch/tensor.py\", line 185, in backward\n",
      "\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 127, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 127, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "    KeyboardInterruptallow_unreachable=True)  # allow_unreachable flag\n",
      "\n",
      "KeyboardInterrupt\n",
      "        allow_unreachable=True)  # allow_unreachable flagallow_unreachable=True)  # allow_unreachable flag\n",
      "\n",
      "KeyboardInterruptKeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node=4 --nnodes=1 --node_rank 0 ddp_example.py --batch_size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10dbb85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
